[合集 \- LLM论文研读(2\)](https://github.com)1\.LLM论文研读: GraphRAG的替代者LightRAG10\-30[2\.LLM论文研读: MindSearch08\-30](https://github.com/mengrennwpu/p/18388868):[悠兔机场](https://xinnongbo.com)收起
## **1\. 背景**


最近有一个很火的开源项目LightRAG，Github6\.4K\+星※，北邮和港大联合出品，是一款微软GraphRAG的优秀替代者，因此本qiang\~得了空闲，读读论文、跑跑源码，遂有了这篇文章。


## 2\. **LightRAG框架**


### **2\.1 已有RAG系统的局限性**


1\) 许多系统仅依赖于平面数据表示(如纯文本)，限制了根据文本中实体间复杂的关系来理解和检索信息的能力。


2\) 许多系统缺乏各种实体及其关系之间保持一致所需的上下文意识，导致可能无法完全解决用户的问题。


### **2\.2  LightRAG的优势**


1\) 引入图结构：将图结构引入文本索引及相关信息检索的环节中，图结构可以有效表示实体及其关系，有利于上下文的连贯性与丰富性。


2\) 综合信息检索: 从所有文档中提取相互依赖的实体的完整上下文，以确保信息检索的综合性。相对于传统的RAG，可能只关注于Chunk后的局部文本，缺乏全局综合信息。


3\) 增强检索效率: 提高基于图结构的知识检索效率，以显著减少响应时间。


4\) 新数据的快速适配: 能够快速适应新的数据更新，确保系统在动态环境中保持相关性。


5\) 减少检索开销: 相对于GraphRAG以社区遍历的方法，LightRAG专注于实体和关系的检索，进而减少开销。


### **2\.3 LightRAG的框架**


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141532244-1377626302.png)


 


LightRAG将基于图结构的文本索引(graph\-based text indexing)无缝地集成到一个双层检索框架(dual\-level retrieval framework)中，因此能够提取实体间复杂的内部关系，提高响应的丰富性和连贯性。


双层检索策略包括低级检索和高级检索，其中低级检索重点关注特定实体及其关系的准确信息，高级检索则包含了广泛的主题信息。


此外，通过将图结构与向量表征相结合，LightRAG促进了相关实体和关系的有效检索，同时基于结构化的知识图谱中相关的信息，增强了结果的全面性。


LightRAG无需重复构建整个索引，降低了计算成本且加速了适配，而且其增量更新算法保障了新数据的及时整合。


#### **2\.3\.1 基于图的文本索引**


1\) 实体及关系抽取：LightRAG先将大文本切分为小文本，然后利用LLM识别并抽取小文本中各种实体及其关系，此举可便于创建综合的知识图谱，prompt示例如下：


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141550936-1700476257.png)


 


2\) 使用LLM性能分析功能生成键值对：使用LLM提供的性能分析函数，为每个实体及每条关系生成一个文本键值对(K, V)，其中K是一个单词或短语，便于高效检索，V是一个文本段落，用于文本片段的总结


3\) 去重以优化图操作：通过去重函数识别并合并来自不同段落的相同实体和关系。有效地减少了与图操作相关的开销，通过最小化图的大小，从而实现更高效的数据处理。


#### **2\.3\.2 双层检索机制**


1\) 在细节层和抽象层分别生成查询键：具体查询以细节为导向，许精确检索特点节点或边相关信息；抽象查询更加概念化，涵盖更广泛的主题、摘要，其并非与特定实体关联。


2\) 双层检索机制：低级检索聚焦于检索特定实体及其属性或关系信息，旨在检索图谱中指定节点或边的精确信息；高级检索处理更广泛的主题，聚合多个相关实体和关系的信息，为高级的概念及摘要提供洞察力。


3\) 集成图以及向量以便高效检索：通过图结构和向量表示，使得检索算法有效地利用局部和全局关键词，简化搜索过程并提高结果的关联性。具体分为如下步骤：


a. 查询关键词提取：针对给定的问题，LightRAG的检索算法首先分别提取局部查询关键词和全部查询关键词


关键词提取的prompt如下：


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141621996-1353684496.png)


 


b. 关键词匹配：检索算法使用向量数据库来匹配局部查询关键词与候选实体，以及全局查询关键词与候选关系(与全局关键词关联)


c. 增强高阶关联性: LightRAG进一步收集已检索到的实体或关系的局部子图，如实体或关系的一跳邻近节点


#### **2\.3\.3 检索增强回答生成**


1\) 使用已检索信息: 利用已检索的信息，包括实体名、实体描述、关系描述以及原文片段，LightRAG使用通用的LLM来生成回答。


2\) 上下文集成及回答生成: 将查询串与上下文进行整合，调用LLM生成答案。


#### **2\.3\.4 整体过程示例**


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141643983-300760108.png)


 


## 3\. **实验**


### **3\.1 数据源**


从UltraDomain基准中选取了4个数据集，分别包括农业、计算机科学、法律、混合集，每个数据集包含60W\-500W个token。


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141650408-2147328473.png)


 


### **3\.2 问题生成**


为了评估LightRAG的性能，首先通过LLM生成5个RAG用户，且为每个用户生成5个任务。每个用户均具有描述信息，详细说明了他们的专业知识和特征，以引发他们提出相关问题。每个用户任务也具有描述信息，强调其中一个用户在于RAG交互时的潜在意图。针对每个用户任务的组合，LLM生成5个需要理解整个数据集的问题。因此，每个数据集共产生125个问题。


问题生成的prompt如下：


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141656744-1069959655.png)


 


### **3\.3 基线模型**


选取的4个基线模型包括Naive RAG, RQ\-RAG, HyDE, GraphRAG。


### **3\.4评价维度及细节**


实验中，向量检索采用nano 向量库，LLM选择GPT\-4o\-mini，每个数据集的分块大小为1200，此外收集参数(gleaning parameter，目的在于仅通过1轮LLM无法完全提取对应的实体或关系，因此该参数旨在增加多次调用LLM)设置为1。


评价标准采用基于LLM的多维度比较方法，使用GPT\-4o\-mini针对LightRAG与每个基线的响应进行排名。主要包含如下4个维度:全面性(回答多大程度解决了问题的所有方面和细节)、多样性(与问题相关的不同观点，答案的多样性和丰富性如何)、接受度(答案是否有效使读者理解主题并做出明确判断)、整体评价(评估前三个标准的累积评价)。


评价prompt如下：


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141704324-607933191.png)


 


### **3\.5 实验结果**


#### **3\.5\.1 与基线RAG方法比较**


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141710932-955932928.png)


 


#### **3\.5\.2 双层检索及基于图结构的索引增强消融结果**


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141716948-1620296633.png)


 


#### **3\.5\.3 具体示例研究**


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141722581-1242830592.png)


 


#### **3\.5\.4 与GraphRAG的成本比较**


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141729113-643828553.png)


 


## 4\. **整体工作流**


图片建议放大，看的更清楚\~


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141734265-526733283.png)


 


 


LightGraph的源码可读性非常强，建议看官们可以基于上面这张流程图，逐步调试LightGraph，以了解其检索和生成两个模块的具体细节。


如果源码层面有问题的话，可以私信或评论进一步交流\~


## **5\.总结**


一句话足矣\~


本文针对开源的LightRAG论文研读以及原理分析，包括核心模块、框架的整体工作流程等内容。


如果想免费获取使用GPT\-4o\-mini的api接口，以及对原理或源码不清楚的看官，可私信或评论沟通。


## **6\.参考**


1\) LightGraph论文地址: [https://arxiv.org/pdf/2410\.05779v1](https://github.com)


2\) LightGraph源码地址：https://github.com/HKUDS/LightRAG


 ![](https://img2024.cnblogs.com/blog/602535/202410/602535-20241030141754307-397596597.png)


 


